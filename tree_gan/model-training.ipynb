{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lQF4P0_cQdFK"
   },
   "outputs": [],
   "source": [
    "colab = False  \n",
    "install = False\n",
    "\n",
    "# Mount Google Drive\n",
    "%%capture\n",
    "if colab:\n",
    "    from google.colab import drive # import drive from google colab\n",
    "\n",
    "    ROOT = \"/content/drive\"     # default location for the drive\n",
    "\n",
    "    drive.mount(ROOT);           # we mount the google drive at /content/drive\n",
    "    \n",
    "    # Set working directory\n",
    "    %cd /content/drive/My Drive/restoration-mapper/tree_gan\n",
    "    \n",
    "if install:\n",
    "    !pip install tensorflow==1.13.1\n",
    "    !pip install -r requirements.txt\n",
    "    !pip install array2gif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations, Imports, Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L7Zag0WcIPR_"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import os\n",
    "config=tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "config.allow_soft_placement=True\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#to make directories\n",
    "import pathlib\n",
    "\n",
    "import sys\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import argparse\n",
    "\n",
    "# P: allows for easy module reloads\n",
    "from importlib import reload\n",
    "\n",
    "# P\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# P\n",
    "import math\n",
    "\n",
    "#L: gives readout of print statements in .py codes\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fXpK-mkyKWCY"
   },
   "outputs": [],
   "source": [
    "class params:\n",
    "  dataset = 'acdc'\n",
    "  #no of training images\n",
    "  no_of_tr_imgs = 'tr3' # Options include: ['tr1', 'tr3', 'tr5', 'tr15', 'tr40']\n",
    "  #combination of training images\n",
    "  comb_tr_imgs = 'c1' # Options include: ['c1', 'c2', 'c3', 'c4', 'c5']\n",
    "\n",
    "  #learning rate of seg unet\n",
    "  lr_seg = 0.00001\n",
    "  # learning rate of generator\n",
    "  lr_gen = 0.0001\n",
    "  # learning rate of discriminator\n",
    "  lr_disc = 0.0001\n",
    "  # lat dim of z sample\n",
    "  z_lat_dim = 100\n",
    "\n",
    "  # ra_en : 0 - disabled, 1 - enabled\n",
    "  ra_en = 0\n",
    "  # select gan type\n",
    "  gan_type = 'lsgan' # Options include: ['lsgan', 'gan', 'wgan-gp','ngan']\n",
    "  # beta value of Adam optimizer\n",
    "  beta_val = 0.9\n",
    "  # to enable the representation of labels with 1 hot encoding\n",
    "  en_1hot = 1\n",
    "\n",
    "  # lamda factors\n",
    "  # for segmenation loss term (lamda_dsc)\n",
    "  lamda_dsc = 1\n",
    "  # adversarial loss term (lamda_adv)\n",
    "  lamda_adv = 1\n",
    "  ### deformation field cGAN specific\n",
    "  # for negative L1 loss on spatial transformation (per-pixel flow field/deformation field) term (lamda_l1_g)\n",
    "  lamda_l1_g = 0.001\n",
    "\n",
    "  ### Intensity field cGAN specific\n",
    "  # for negative L1 loss on transformation (additive intensity field) term (lamda_l1_i)\n",
    "  lamda_l1_i = 0.001\n",
    "\n",
    "  #version of run\n",
    "  ver = 0\n",
    "\n",
    "  #data aug - 0 - disabled, 1 - enabled\n",
    "  data_aug_seg = 1 # Options include: [0,1]\n",
    "\n",
    "  # segmentation loss to optimize\n",
    "  # 0 for weighted cross entropy, 1 for dice score loss\n",
    "  dsc_loss = 0 # Options include: [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_en_val=params.ra_en\n",
    "if(params.ra_en==1):\n",
    "    params.ra_en=True\n",
    "else:\n",
    "    params.ra_en=False\n",
    "\n",
    "import experiment_init.init_acdc as cfg\n",
    "import experiment_init.data_cfg_acdc as data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# class loaders\n",
    "# ####################################\n",
    "#  load dataloader object\n",
    "from dataloaders import dataloaderObj\n",
    "dt = dataloaderObj(cfg)\n",
    "\n",
    "\n",
    "#print('set acdc orig img dataloader handle')\n",
    "orig_img_dt=dt.load_acdc_imgs\n",
    "\n",
    "#  load model object\n",
    "import models \n",
    "model = models.modelObj(cfg)\n",
    "#  load f1_utils object\n",
    "from f1_utils import f1_utilsObj\n",
    "f1_util = f1_utilsObj(cfg,dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#define save_dir for the model\n",
    "save_dir = 'models/'\n",
    "if not os.path.exists(save_dir[:-1]):\n",
    "    os.makedirs(save_dir[:-1])\n",
    "print('save_dir: ',save_dir)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# load train and val images\n",
    "#train_list = data_list.train_data(params.no_of_tr_imgs,params.comb_tr_imgs)\n",
    "#load train data cropped images directly\n",
    "print('loading train imgs')\n",
    "train_imgs,train_labels = dt.load_imgs(dataset= 'lab')\n",
    "# P: switching dimensions before feeding into minibatch function\n",
    "train_imgs = np.moveaxis(train_imgs,3,0)\n",
    "train_labels = np.moveaxis(train_labels,2,0)\n",
    "print(train_imgs.shape)\n",
    "print(train_labels.shape)\n",
    "#D: we might have to adjust this if our mini sample is too small compared to batch size\n",
    "# if(params.no_of_tr_imgs=='tr1'):\n",
    "#     train_imgs_copy=np.copy(train_imgs)\n",
    "#     train_labels_copy=np.copy(train_labels)\n",
    "#     while(train_imgs.shape[2]<cfg.batch_size):\n",
    "#         train_imgs=np.concatenate((train_imgs,train_imgs_copy),axis=2)\n",
    "#         train_labels=np.concatenate((train_labels,train_labels_copy),axis=2)\n",
    "#     del train_imgs_copy,train_labels_copy\n",
    "\n",
    "#load both val data and its cropped images\n",
    "print('loading val imgs')\n",
    "val_imgs,val_labels = dt.load_imgs(dataset= 'val')\n",
    "val_n = val_imgs.shape[3]\n",
    "#L: change to (20,16,16,16)\n",
    "val_imgs = np.moveaxis(val_imgs,3,0)\n",
    "val_labels = np.moveaxis(val_labels,2,0)\n",
    "print('val image dims after reshape')\n",
    "print(val_imgs.shape)\n",
    "print(val_labels.shape)\n",
    "\n",
    "# # load unlabeled images\n",
    "#unl_list = data_list.unlabeled_data()\n",
    "print('loading unlabeled imgs')\n",
    "unlabeled_imgs=dt.load_imgs(dataset= 'unlab')\n",
    "# P: switching dimensions before feeding into minibatch function\n",
    "unlabeled_imgs = np.moveaxis(unlabeled_imgs,3,0)\n",
    "print('unlabeled_imgs',unlabeled_imgs.shape)\n",
    "\n",
    "\n",
    "# get test list\n",
    "#print('get test imgs list')\n",
    "#D: will have to add this back once test data created\n",
    "#test_list = data_list.test_data()\n",
    "#D: will have to figure out struct name in our case - it is used for computing the \n",
    "# model performance, segmentation mask etc. in f1_util.pred_segs_acdc_test_subjs\n",
    "#struct_name=cfg.struct_name\n",
    "val_step_update=cfg.val_step_update\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "\n",
    "def get_samples(labeled_imgs,unlabeled_imgs):\n",
    "    # sample z vectors from Gaussian Distribution\n",
    "    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "    # sample Unlabeled data shuffled batch\n",
    "    unld_img_batch=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    # sample Labelled data shuffled batch\n",
    "    ld_img_batch=shuffle_minibatch([labeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    return z_samples,ld_img_batch,unld_img_batch\n",
    "\n",
    "def plt_func(sess,ae,save_dir,z_samples,ld_img_batch,unld_img_batch,index=0):\n",
    "    # plot deformed images for an fixed input image and different per-pixel flow vectors generated from sampled z values\n",
    "    ld_img_tmp=np.zeros_like(ld_img_batch)\n",
    "    # select one 2D image from the batch and apply different z's sampled over this selected image\n",
    "    for i in range(0,20):\n",
    "        ld_img_tmp[i,:,:,0]=ld_img_batch[index,:,:,0]\n",
    "\n",
    "    flow_vec,y_geo_deformed,z_cost=sess.run([ae['flow_vec'],ae['y_trans'],ae['z_cost']], feed_dict={ae['x_l']: ld_img_tmp, ae['z']:z_samples,\\\n",
    "                          ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: False})\n",
    "\n",
    "    f1_util.plot_deformed_imgs(ld_img_tmp,y_geo_deformed,flow_vec,save_dir,index=index)\n",
    "\n",
    "    # Plot gif of all the deformed images generated for the fixed input image\n",
    "    f1_util.write_gif_func(ip_img=y_geo_deformed, imsize=(cfg.img_size_x,cfg.img_size_y),save_dir=save_dir,index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# Define checkpoint file to save CNN architecture and learnt hyperparameters\n",
    "checkpoint_filename='unet_'+str(params.dataset)\n",
    "logs_path = str(save_dir)+'tensorflow_logs/'\n",
    "best_model_dir=str(save_dir)+'best_model/'\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L: set class weights so adapts to training data if it changes\n",
    "ntrlabs = np.sum(np.unique(train_labels, return_counts = True)[1])\n",
    "propnotree = (ntrlabs - np.unique(train_labels, return_counts = True)[1][1])/ntrlabs\n",
    "proptree = 1-propnotree\n",
    "classweight = tf.constant([[proptree, propnotree]],name='class_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#  training parameters\n",
    "start_epoch=0\n",
    "#L: make this 10 for quick training to test\n",
    "n_epochs = 1000\n",
    "disp_step=400\n",
    "print_step=2000\n",
    "# no of iterations to train just the segmentation network using the labeled data without any cGAN generated data\n",
    "seg_tr_limit=200\n",
    "f1_val_prev=0.1\n",
    "threshold_f1=0.000001\n",
    "pathlib.Path(best_model_dir).mkdir(parents=True, exist_ok=True)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8cqzpqbwnvoZ"
   },
   "source": [
    "## Deformation Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QamwiCTOQdJV"
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "# Define deformation field generator model graph\n",
    "ae = model.spatial_generator_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n",
    "                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n",
    "                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n",
    "                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_g=params.lamda_l1_g,\n",
    "                        class_weights = classweight, num_channels = cfg.num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ja6WdYEQdJ0"
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "# define graph to compute deformed image given an per-pixel flow vector and input image\n",
    "#L: change this to new function, deform net clip\n",
    "df_ae= model.deform_netclip()\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T64RuzRgQdJ_"
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "#writer for train summary\n",
    "train_writer = tf.summary.FileWriter(logs_path)\n",
    "#writer for dice score and val summary\n",
    "dsc_writer = tf.summary.FileWriter(logs_path)\n",
    "val_sum_writer = tf.summary.FileWriter(logs_path)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# create a session and initialize variable to use the graph\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Save training data\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qfnJ_KT5nul0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run for n_epochs\n",
    "\n",
    "# arrays to store metrics from every epoch\n",
    "seg_cost_epoch = np.array([])\n",
    "seg_acc_epoch = np.array([])\n",
    "g_loss_epoch = np.array([])\n",
    "d_loss_epoch = np.array([])\n",
    "val_acc_epoch = np.array([])\n",
    "val_f1_epoch = np.array([])\n",
    "\n",
    "\n",
    "for epoch_i in range(start_epoch,n_epochs):\n",
    "    \n",
    "\n",
    "    \n",
    "    # sample Unlabeled shuffled batch\n",
    "    unld_img_batches=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),labels_present=0)\n",
    "    # P: already did this above\n",
    "#     unld_img_batch = np.moveaxis(unld_img_batch,3,0).reshape(20,16,16,16)\n",
    "    \n",
    "    # sample Labelled shuffled batch\n",
    "    ld_img_batches,ld_label_batches=shuffle_minibatch([train_imgs,train_labels],batch_size=cfg.batch_size)\n",
    "    # P: already did this above\n",
    "#     ld_img_batch = np.moveaxis(ld_img_batch,3,0)\n",
    "#     ld_label_batch = np.moveaxis(ld_label_batch,2,0)\n",
    "\n",
    "    minibatches = math.floor(len(train_imgs)/cfg.batch_size+0.5)\n",
    "    for b in range(minibatches):\n",
    "        \n",
    "        unld_img_batch = unld_img_batches[b]\n",
    "        ld_img_batch = ld_img_batches[b]\n",
    "        ld_label_batch = ld_label_batches[b]\n",
    "\n",
    "        # sample z's from Gaussian Distribution\n",
    "        z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "        if(cfg.aug_en==1):\n",
    "            # Apply affine transformations\n",
    "            ld_img_batch,ld_label_batch=augmentation_function([ld_img_batch,ld_label_batch],dt)\n",
    "            unld_img_batch=augmentation_function([unld_img_batch],dt,labels_present=0)\n",
    "\n",
    "        ld_img_batch_tmp=np.copy(ld_img_batch)\n",
    "        # Compute 1 hot encoding of the segmentation mask labels\n",
    "        ld_label_batch_1hot = sess.run(df_ae['y_tmp_1hot'],feed_dict={df_ae['y_tmp']:ld_label_batch})    \n",
    "\n",
    "        if(epoch_i>=seg_tr_limit):\n",
    "            # sample the batch of images and apply deformation field generated by the Generator network on these which are used for the remaining 9500 epochs\n",
    "            # Batch comprosed of both deformed image,label pairs and original affine transformed image, label pairs\n",
    "            ld_label_batch_tmp=np.copy(ld_label_batch)\n",
    "            ###########################\n",
    "            ## use Deformation field cGAN to generate additional augmented image,label pairs from labeled samples\n",
    "            flow_vec,ld_img_batch=sess.run([ae['flow_vec'],ae['y_trans']],\\\n",
    "                                        feed_dict={ae['x_l']: ld_img_batch_tmp, ae['z']:z_samples, ae['train_phase']: False})\n",
    "\n",
    "            ld_label_batch=sess.run([df_ae['deform_y_1hot']],feed_dict={df_ae['y_tmp']:ld_label_batch,df_ae['flow_v']:flow_vec})\n",
    "            ld_label_batch=ld_label_batch[0]\n",
    "\n",
    "            ###########################\n",
    "            #shuffle the quantity/number of images chosen from deformation cGAN augmented images and rest are original images with conventional affine transformations\n",
    "            no_orig=np.random.randint(5, high=15)\n",
    "            ld_img_batch[0:no_orig] = ld_img_batch_tmp[0:no_orig]\n",
    "            if(params.en_1hot==1):\n",
    "                ld_label_batch[0:no_orig] = ld_label_batch_1hot[0:no_orig]\n",
    "            #D: this else statement here baffles me - we will have to look into it at some later point - why would you turn images back from 1hot to\n",
    "            # regular 1d classes with that argmax? When the ld_label batch assumes 1hot input? and especially in a scenario called 1hot == 0\n",
    "            else:\n",
    "                ld_label_batch = np.argmax(ld_label_batch,axis=3)\n",
    "                ld_label_batch[0:no_orig] = ld_label_batch_tmp[0:no_orig]\n",
    "\n",
    "            #Pick equal number of images from each category\n",
    "            # ld_img_batch[0:10]=ld_img_batch_tmp[0:10]\n",
    "            # ld_label_batch[0:10]=ld_label_batch_1hot[0:10]\n",
    "\n",
    "        elif(epoch_i<seg_tr_limit):\n",
    "            # sample only labeled data batches to optimize only Segmentation Network for initial 500 epochs\n",
    "            ld_img_batch=ld_img_batch\n",
    "            unld_img_batch=unld_img_batch\n",
    "            ld_label_batch=ld_label_batch_1hot\n",
    "\n",
    "        if(epoch_i<seg_tr_limit):\n",
    "            #Optimize only Segmentation Network for initial 500 epochs\n",
    "            train_summary, seg_cost, _ =sess.run([ae['seg_summary'], ae['seg_cost'], ae['optimizer_unet_seg']], feed_dict={ae['x']: ld_img_batch, ae['y_l']: ld_label_batch,\\\n",
    "                                       ae['select_mask']: False, ae['train_phase']: True})\n",
    "\n",
    "            if(b==minibatches-1):\n",
    "                pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, ld_img_batch)\n",
    "                acc = np.mean(f1_util.calc_accuracy(np.argmax(pred_sf_mask, -1),np.argmax(ld_label_batch, -1)))\n",
    "                seg_cost_epoch = np.append(seg_cost_epoch,seg_cost)\n",
    "                seg_acc_epoch = np.append(seg_acc_epoch,acc)\n",
    "                print(\"Epoch: \", epoch_i, \"Seg loss: \", np.mean(seg_cost_epoch), \"Seg acc: \", np.mean(seg_acc_epoch))\n",
    "\n",
    "\n",
    "         #Optimize Generator (G), Discriminator (D) and Segmentation (S) networks for the remaining 9500 epochs       \n",
    "        if(epoch_i>seg_tr_limit):   \n",
    "\n",
    "            # update both Generator and Segmentation Net parameters in the framework using total loss value\n",
    "            train_summary, z_cost, cost_a1_seg, seg_cost, _ =sess.run([ae['train_summary'],\\\n",
    "                                                                       ae['z_cost'],  ae['cost_a1_seg'], ae['seg_cost'], ae['optimizer_l2_both_gen_unet']],\\\n",
    "                                                                       feed_dict={ae['x']: ld_img_batch,ae['x_l']: ld_img_batch,ae['y_l']: ld_label_batch,\\\n",
    "                                       ae['z']:z_samples, ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n",
    "            # update Discriminator Net (D) parameters in the setup using only discriminator loss\n",
    "            train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_disc']], feed_dict={ae['x']: ld_img_batch, ae['x_l']: ld_img_batch, ae['z']:z_samples,\\\n",
    "                                  ae['y_l']: ld_label_batch,ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n",
    "\n",
    "            if(b==minibatches-1):\n",
    "                pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, ld_img_batch)\n",
    "                acc = np.mean(f1_util.calc_accuracy(np.argmax(pred_sf_mask, -1),np.argmax(ld_label_batch, -1)))\n",
    "                seg_cost_epoch = np.append(seg_cost_epoch,seg_cost)\n",
    "                seg_acc_epoch = np.append(seg_acc_epoch,acc)\n",
    "                g_loss_epoch = np.append(g_loss_epoch, cost_a1_seg)\n",
    "                d_loss_epoch = np.append(d_loss_epoch, z_cost)\n",
    "                print(\"Epoch: \", epoch_i, \"Seg loss: \", np.mean(seg_cost_epoch), \"Seg acc: \", np.mean(seg_acc_epoch), \"Disc loss: \", z_cost, \"Gen loss: \", cost_a1_seg,)\n",
    "\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        train_writer.add_summary(train_summary, epoch_i)\n",
    "        train_writer.flush()\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        ##Save the model with best DSC for Validation Image\n",
    "        f1_arr=[]\n",
    "\n",
    "        # Compute segmentation mask and dice_score validation data\n",
    "        val_pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, val_imgs)\n",
    "        f1_val = np.mean(f1_util.calc_f1_score(np.argmax(val_pred_sf_mask, -1),val_labels))\n",
    "        val_f1_epoch = np.append(val_f1_epoch, f1_val)\n",
    "        val_acc = np.mean(f1_util.calc_accuracy(np.argmax(val_pred_sf_mask, -1),val_labels))\n",
    "        val_acc_epoch = np.append(val_acc_epoch, val_acc)\n",
    "\n",
    "        print(\"Epoch: \", epoch_i, \"F1 (val): \", f1_val, \"Acc (val): \", val_acc)\n",
    "        \n",
    "\n",
    "\n",
    "        # if (f1_val-f1_val_prev>threshold_f1 and epoch_i!=start_epoch):\n",
    "        #     print(\"prev f1_val; present_f1_val\", f1_val_prev, f1_val)\n",
    "        #     f1_val_prev = f1_val\n",
    "        #     # to save the best model with maximum dice score over the entire n_epochs\n",
    "        #     print(\"best model saved at epoch no. \", epoch_i)\n",
    "        #     mp_best = str(best_model_dir) + str(checkpoint_filename) + '_best_model_epoch_' + str(epoch_i) + '.ckpt'\n",
    "        #     saver.save(sess, mp_best)\n",
    "\n",
    "        # # calc. and save validation image dice summary\n",
    "        # dsc_summary_msg = sess.run(ae['val_f1_summary'], feed_dict={ae['f1']:f1_val})\n",
    "        # val_sum_writer.add_summary(dsc_summary_msg, epoch_i)\n",
    "        # val_sum_writer.flush()\n",
    "\n",
    "    if ((epoch_i==n_epochs-1) and (epoch_i != start_epoch)):\n",
    "        # model saved at last epoch\n",
    "        mp = str(save_dir) + str(checkpoint_filename) + '_epochs_' + str(epoch_i) + '.ckpt'\n",
    "        saver.save(sess, mp)\n",
    "        try:\n",
    "            mp_best\n",
    "        except NameError:\n",
    "            mp_best=mp\n",
    "\n",
    "sess.close()\n",
    "######################################\n",
    "# restore best model and predict segmentations on test subjects\n",
    "saver_new = tf.train.Saver()\n",
    "sess_new = tf.Session(config=config)\n",
    "saver_new.restore(sess_new, mp_best)\n",
    "print(\"best model chkpt name\",mp_best)\n",
    "print(\"Model restored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('TkAgg')\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('Batch Segmentation Cost', color='red')\n",
    "ln1 = ax1.plot(seg_cost_epoch, color='red', label='SegCost')\n",
    "ax1.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "ax2.set_ylabel('F1 Validation Score', color='blue')  # we already handled the x-label with ax1\n",
    "ln2 = ax2.plot(seg_acc_epoch, color ='green', label = 'Seg Acc')\n",
    "#D: this is a hacky way of getting the validation data scores that are only calculated every few epochs to show properly on this graph\n",
    "# it basically just repeats every value val_step_update number of times, so that it is flat for val_step_update epochs and thus works on the same x axis\n",
    "ln3 = ax2.plot([i for b in map(lambda x:[x] if not isinstance(x, list) else x, [list(itertools.repeat(x,val_step_update)) for x in val_f1_epoch]) for i in b], color='blue', label = \"F1score\")\n",
    "ln4 = ax2.plot([i for b in map(lambda x:[x] if not isinstance(x, list) else x, [list(itertools.repeat(x,val_step_update)) for x in val_acc_epoch]) for i in b], color=\"orange\", label = \"Valid. Acc.\")\n",
    "ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "fig.legend(loc=\"center right\", bbox_to_anchor=(1,0.9), bbox_transform=ax1.transAxes)\n",
    "\n",
    "plt.title(\"Tree GAN Training (10k Epochs)\")\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#plt.savefig('../data/FES Team/Naive CCN Training.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('Batch Generator Loss', color='red')\n",
    "ln1 = ax1.plot(g_loss_epoch, color='red', label='Gen Loss')\n",
    "ax1.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "ax2.set_ylabel('Batch Discrimanotr Loss', color='blue')  # we already handled the x-label with ax1\n",
    "ln2 = ax2.plot(d_loss_epoch, color ='green', label = 'Disc Loss')\n",
    "ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "fig2.legend(loc=\"center right\", bbox_to_anchor=(1,0.9), bbox_transform=ax1.transAxes)\n",
    "\n",
    "plt.title(\"GAN Losses\")\n",
    "\n",
    "fig2.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#plt.savefig('../data/FES Team/Naive CCN Training.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITKtK1haQdKG"
   },
   "outputs": [],
   "source": [
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vOCLtLtAQdKJ"
   },
   "outputs": [],
   "source": [
    "logs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6loZeYJQdKW"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard.notebook\n",
    "%tensorboard --logdir data_aug_seg/models/dabes/tflogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qkl7qlDNQdKZ"
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# To compute inference on test images on the model that yields best dice score on validation images\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir,orig_img_dt,test_list,struct_name)\n",
    "#########################\n",
    "# To plot the generated augmented images from the trained deformation cGAN\n",
    "for j in range(0,5):\n",
    "    z_samples,ld_img_batch,unld_img_batch=get_samples(train_imgs,unlabeled_imgs)\n",
    "    save_dir_tmp=str(save_dir)+'/ep_best_model/'\n",
    "    plt_func(sess_new,ae,save_dir_tmp,z_samples,ld_img_batch,unld_img_batch,index=j)\n",
    "######################################\n",
    "#D: we will have to put back some of these validation data references\n",
    "# To compute inference on validation images on the best model\n",
    "#save_dir_tmp=str(save_dir)+'/val_imgs/'\n",
    "#f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir_tmp,orig_img_dt,val_list,struct_name)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cI-JoaIAOeFl"
   },
   "source": [
    "# Train Additive Intensity Field GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intae = model.intensity_transform_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n",
    "                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n",
    "                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n",
    "                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_i=params.lamda_l1_i,\n",
    "                        class_weights = classweight, num_channels = cfg.num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# define graph to compute deformed image given an per-pixel flow vector and input image\n",
    "#L: change this to new function, deform net clip\n",
    "df_intae= model.deform_netclip()\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "#writer for train summary\n",
    "train_writer = tf.summary.FileWriter(logs_path)\n",
    "#writer for dice score and val summary\n",
    "dsc_writer = tf.summary.FileWriter(logs_path)\n",
    "val_sum_writer = tf.summary.FileWriter(logs_path)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# create a session and initialize variable to use the graph\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Save training data\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#L: copying over deformation training flow,\n",
    "#all changes that are not ae -> intae will be marked L*\n",
    "# Run for n_epochs\n",
    "\n",
    "# arrays to store metrics from every epoch\n",
    "seg_cost_epoch = np.array([])\n",
    "seg_acc_epoch = np.array([])\n",
    "g_loss_epoch = np.array([])\n",
    "d_loss_epoch = np.array([])\n",
    "val_acc_epoch = np.array([])\n",
    "val_f1_epoch = np.array([])\n",
    "\n",
    "\n",
    "for epoch_i in range(start_epoch,n_epochs):\n",
    "    \n",
    "\n",
    "    \n",
    "    # sample Unlabeled shuffled batch\n",
    "    unld_img_batches=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),labels_present=0)\n",
    "    # P: already did this above\n",
    "#     unld_img_batch = np.moveaxis(unld_img_batch,3,0).reshape(20,16,16,16)\n",
    "    \n",
    "    # sample Labelled shuffled batch\n",
    "    ld_img_batches,ld_label_batches=shuffle_minibatch([train_imgs,train_labels],batch_size=cfg.batch_size)\n",
    "    # P: already did this above\n",
    "#     ld_img_batch = np.moveaxis(ld_img_batch,3,0)\n",
    "#     ld_label_batch = np.moveaxis(ld_label_batch,2,0)\n",
    "\n",
    "    minibatches = math.floor(len(train_imgs)/cfg.batch_size+0.5)\n",
    "    for b in range(minibatches):\n",
    "        \n",
    "        unld_img_batch = unld_img_batches[b]\n",
    "        ld_img_batch = ld_img_batches[b]\n",
    "        ld_label_batch = ld_label_batches[b]\n",
    "\n",
    "        # sample z's from Gaussian Distribution\n",
    "        z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "        if(cfg.aug_en==1):\n",
    "            # Apply affine transformations\n",
    "            ld_img_batch,ld_label_batch=augmentation_function([ld_img_batch,ld_label_batch],dt)\n",
    "            unld_img_batch=augmentation_function([unld_img_batch],dt,labels_present=0)\n",
    "\n",
    "        ld_img_batch_tmp=np.copy(ld_img_batch)\n",
    "        # Compute 1 hot encoding of the segmentation mask labels\n",
    "        ld_label_batch_1hot = sess.run(df_intae['y_tmp_1hot'],feed_dict={df_intae['y_tmp']:ld_label_batch})    \n",
    "\n",
    "        if(epoch_i>=seg_tr_limit):\n",
    "            # sample the batch of images and apply deformation field generated by the Generator network on these which are used for the remaining 9500 epochs\n",
    "            # Batch comprosed of both deformed image,label pairs and original affine transformed image, label pairs\n",
    "            ld_label_batch_tmp=np.copy(ld_label_batch)\n",
    "            ###########################\n",
    "            #L*: change this portion to additive intensity code, no flow_vec, no deformation of labels\n",
    "            ## use Deformation field cGAN to generate additional augmented image,label pairs from labeled samples\n",
    "            _,ld_img_batch=sess.run([intae['int_c1'],intae['y_int']],\\\n",
    "                                        feed_dict={intae['x']: ld_img_batch_tmp, intae['z']:z_samples, intae['train_phase']: False})\n",
    "\n",
    "            ld_label_batch=ld_label_batch_1hot\n",
    "\n",
    "            ###########################\n",
    "            #shuffle the quantity/number of images chosen from deformation cGAN augmented images and rest are original images with conventional affine transformations\n",
    "            no_orig=np.random.randint(5, high=15)\n",
    "            ld_img_batch[0:no_orig] = ld_img_batch_tmp[0:no_orig]\n",
    "            if(params.en_1hot==1):\n",
    "                ld_label_batch[0:no_orig] = ld_label_batch_1hot[0:no_orig]\n",
    "            #D: this else statement here baffles me - we will have to look into it at some later point - why would you turn images back from 1hot to\n",
    "            # regular 1d classes with that argmax? When the ld_label batch assumes 1hot input? and especially in a scenario called 1hot == 0\n",
    "            else:\n",
    "                ld_label_batch = np.argmax(ld_label_batch,axis=3)\n",
    "                ld_label_batch[0:no_orig] = ld_label_batch_tmp[0:no_orig]\n",
    "\n",
    "            #Pick equal number of images from each category\n",
    "            # ld_img_batch[0:10]=ld_img_batch_tmp[0:10]\n",
    "            # ld_label_batch[0:10]=ld_label_batch_1hot[0:10]\n",
    "\n",
    "        elif(epoch_i<seg_tr_limit):\n",
    "            # sample only labeled data batches to optimize only Segmentation Network for initial 500 epochs\n",
    "            ld_img_batch=ld_img_batch\n",
    "            unld_img_batch=unld_img_batch\n",
    "            ld_label_batch=ld_label_batch_1hot\n",
    "\n",
    "        if(epoch_i<seg_tr_limit):\n",
    "            #Optimize only Segmentation Network for initial 500 epochs\n",
    "            train_summary, seg_cost, _ =sess.run([intae['seg_summary'], intae['seg_cost'], intae['optimizer_unet_seg']], feed_dict={intae['x']: ld_img_batch, intae['y_l']: ld_label_batch,\\\n",
    "                                       intae['select_mask']: False, intae['train_phase']: True})\n",
    "\n",
    "            if(b==minibatches-1):\n",
    "                pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, intae, ld_img_batch)\n",
    "                acc = np.mean(f1_util.calc_accuracy(np.argmax(pred_sf_mask, -1),np.argmax(ld_label_batch, -1)))\n",
    "                seg_cost_epoch = np.append(seg_cost_epoch,seg_cost)\n",
    "                seg_acc_epoch = np.append(seg_acc_epoch,acc)\n",
    "                print(\"Epoch: \", epoch_i, \"Seg loss: \", np.mean(seg_cost_epoch), \"Seg acc: \", np.mean(seg_acc_epoch))\n",
    "\n",
    "\n",
    "         #Optimize Generator (G), Discriminator (D) and Segmentation (S) networks for the remaining 9500 epochs       \n",
    "        if(epoch_i>seg_tr_limit):   \n",
    "\n",
    "            # update both Generator and Segmentation Net parameters in the framework using total loss value\n",
    "            #L*: remove x_l, not called in additive intensity field generator\n",
    "            train_summary, z_cost, cost_a1_seg, seg_cost, _ =sess.run([intae['train_summary'],\\\n",
    "                                                                       intae['z_cost'],  intae['cost_a1_seg'], intae['seg_cost'], intae['optimizer_l2_both_gen_unet']],\\\n",
    "                                                                       feed_dict={intae['x']: ld_img_batch,intae['y_l']: ld_label_batch,\\\n",
    "                                       intae['z']:z_samples, intae['x_unl']: unld_img_batch, intae['select_mask']: True, intae['train_phase']: True})\n",
    "            # update Discriminator Net (D) parameters in the setup using only discriminator loss\n",
    "            train_summary,_ =sess.run([intae['train_summary'],intae['optimizer_disc']], feed_dict={intae['x']: ld_img_batch, intae['z']:z_samples,\\\n",
    "                                  intae['y_l']: ld_label_batch,intae['x_unl']: unld_img_batch, intae['select_mask']: True, intae['train_phase']: True})\n",
    "\n",
    "            if(b==minibatches-1):\n",
    "                pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, intae, ld_img_batch)\n",
    "                acc = np.mean(f1_util.calc_accuracy(np.argmax(pred_sf_mask, -1),np.argmax(ld_label_batch, -1)))\n",
    "                seg_cost_epoch = np.append(seg_cost_epoch,seg_cost)\n",
    "                seg_acc_epoch = np.append(seg_acc_epoch,acc)\n",
    "                g_loss_epoch = np.append(g_loss_epoch, cost_a1_seg)\n",
    "                d_loss_epoch = np.append(d_loss_epoch, z_cost)\n",
    "                print(\"Epoch: \", epoch_i, \"Seg loss: \", np.mean(seg_cost_epoch), \"Seg acc: \", np.mean(seg_acc_epoch), \"Disc loss: \", z_cost, \"Gen loss: \", cost_a1_seg,)\n",
    "\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        train_writer.add_summary(train_summary, epoch_i)\n",
    "        train_writer.flush()\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        ##Save the model with best DSC for Validation Image\n",
    "        f1_arr=[]\n",
    "\n",
    "        # Compute segmentation mask and dice_score validation data\n",
    "        val_pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, intae, val_imgs)\n",
    "        f1_val = np.mean(f1_util.calc_f1_score(np.argmax(val_pred_sf_mask, -1),val_labels))\n",
    "        val_f1_epoch = np.append(val_f1_epoch, f1_val)\n",
    "        val_acc = np.mean(f1_util.calc_accuracy(np.argmax(val_pred_sf_mask, -1),val_labels))\n",
    "        val_acc_epoch = np.append(val_acc_epoch, val_acc)\n",
    "\n",
    "        print(\"Epoch: \", epoch_i, \"F1 (val): \", f1_val, \"Acc (val): \", val_acc)\n",
    "        \n",
    "\n",
    "\n",
    "        # if (f1_val-f1_val_prev>threshold_f1 and epoch_i!=start_epoch):\n",
    "        #     print(\"prev f1_val; present_f1_val\", f1_val_prev, f1_val)\n",
    "        #     f1_val_prev = f1_val\n",
    "        #     # to save the best model with maximum dice score over the entire n_epochs\n",
    "        #     print(\"best model saved at epoch no. \", epoch_i)\n",
    "        #     mp_best = str(best_model_dir) + str(checkpoint_filename) + '_best_model_epoch_' + str(epoch_i) + '.ckpt'\n",
    "        #     saver.save(sess, mp_best)\n",
    "\n",
    "        # # calc. and save validation image dice summary\n",
    "        # dsc_summary_msg = sess.run(intae['val_f1_summary'], feed_dict={intae['f1']:f1_val})\n",
    "        # val_sum_writer.add_summary(dsc_summary_msg, epoch_i)\n",
    "        # val_sum_writer.flush()\n",
    "\n",
    "    if ((epoch_i==n_epochs-1) and (epoch_i != start_epoch)):\n",
    "        # model saved at last epoch\n",
    "        mp = str(save_dir) + str(checkpoint_filename) + '_epochs_' + str(epoch_i) + '.ckpt'\n",
    "        saver.save(sess, mp)\n",
    "        try:\n",
    "            mp_best\n",
    "        except NameError:\n",
    "            mp_best=mp\n",
    "\n",
    "sess.close()\n",
    "######################################\n",
    "# restore best model and predict segmentations on test subjects\n",
    "saver_new = tf.train.Saver()\n",
    "sess_new = tf.Session(config=config)\n",
    "saver_new.restore(sess_new, mp_best)\n",
    "print(\"best model chkpt name\",mp_best)\n",
    "print(\"Model restored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use('TkAgg')\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('Batch Segmentation Cost', color='red')\n",
    "ln1 = ax1.plot(seg_cost_epoch, color='red', label='SegCost')\n",
    "ax1.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "ax2.set_ylabel('F1 Validation Score', color='blue')  # we already handled the x-label with ax1\n",
    "ln2 = ax2.plot(seg_acc_epoch, color ='green', label = 'Seg Acc')\n",
    "#D: this is a hacky way of getting the validation data scores that are only calculated every few epochs to show properly on this graph\n",
    "# it basically just repeats every value val_step_update number of times, so that it is flat for val_step_update epochs and thus works on the same x axis\n",
    "ln3 = ax2.plot([i for b in map(lambda x:[x] if not isinstance(x, list) else x, [list(itertools.repeat(x,val_step_update)) for x in val_f1_epoch]) for i in b], color='blue', label = \"F1score\")\n",
    "ln4 = ax2.plot([i for b in map(lambda x:[x] if not isinstance(x, list) else x, [list(itertools.repeat(x,val_step_update)) for x in val_acc_epoch]) for i in b], color=\"orange\", label = \"Valid. Acc.\")\n",
    "ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "fig.legend(loc=\"center right\", bbox_to_anchor=(1,0.9), bbox_transform=ax1.transAxes)\n",
    "\n",
    "plt.title(\"Tree GAN Training (10k Epochs)\")\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#plt.savefig('../data/FES Team/Naive CCN Training.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('Batch Generator Loss', color='red')\n",
    "ln1 = ax1.plot(g_loss_epoch, color='red', label='Gen Loss')\n",
    "ax1.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "ax2.set_ylabel('Batch Discrimanotr Loss', color='blue')  # we already handled the x-label with ax1\n",
    "ln2 = ax2.plot(d_loss_epoch, color ='green', label = 'Disc Loss')\n",
    "ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "fig2.legend(loc=\"center right\", bbox_to_anchor=(1,0.9), bbox_transform=ax1.transAxes)\n",
    "\n",
    "plt.title(\"GAN Losses\")\n",
    "\n",
    "fig2.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#plt.savefig('../data/FES Team/Naive CCN Training.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gGmOCYBzOi3g"
   },
   "outputs": [],
   "source": [
    "ra_en_val=params.ra_en\n",
    "if(params.ra_en==1):\n",
    "    params.ra_en=True\n",
    "else:\n",
    "    params.ra_en=False\n",
    "\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    #print('load acdc configs')\n",
    "    import experiment_init.init_acdc as cfg\n",
    "    import experiment_init.data_cfg_acdc as data_list\n",
    "else:\n",
    "    raise ValueError(params.dataset)\n",
    "\n",
    "######################################\n",
    "# class loaders\n",
    "# ####################################\n",
    "#  load dataloader object\n",
    "from dataloaders import dataloaderObj\n",
    "dt = dataloaderObj(cfg)\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    #print('set acdc orig img dataloader handle')\n",
    "    orig_img_dt=dt.load_acdc_imgs\n",
    "\n",
    "#  load model object\n",
    "from models import modelObj\n",
    "model = modelObj(cfg)\n",
    "#  load f1_utils object\n",
    "from f1_utils import f1_utilsObj\n",
    "f1_util = f1_utilsObj(cfg,dt)\n",
    "\n",
    "######################################\n",
    "#define save_dir for the model\n",
    "save_dir=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/tr_intensity_cgan_unet/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)+'/'\n",
    "\n",
    "if(params.data_aug_seg==0):\n",
    "    save_dir=str(save_dir)+'no_data_aug/'\n",
    "    cfg.aug_en=params.data_aug_seg\n",
    "else:\n",
    "    save_dir=str(save_dir)+'with_data_aug/'\n",
    "\n",
    "save_dir=str(save_dir)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+'_lamda_i_'+str(params.lamda_l1_i)+'/'+\\\n",
    "         str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+\\\n",
    "         '/unet_model_beta1_'+str(params.beta_val)+'_lr_seg_'+str(params.lr_seg)+'_lr_gen_'+str(params.lr_gen)+'_lr_disc_'+str(params.lr_disc)+'/'\n",
    "\n",
    "print('save_dir',save_dir)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# load train and val images\n",
    "train_list = data_list.train_data(params.no_of_tr_imgs,params.comb_tr_imgs)\n",
    "# load train data cropped images directly\n",
    "print('loading train imgs')\n",
    "train_imgs,train_labels = dt.load_img_labels(train_list)\n",
    "\n",
    "if(params.no_of_tr_imgs=='tr1'):\n",
    "    train_imgs_copy=np.copy(train_imgs)\n",
    "    train_labels_copy=np.copy(train_labels)\n",
    "    while(train_imgs.shape[2]<cfg.batch_size):\n",
    "        train_imgs=np.concatenate((train_imgs,train_imgs_copy),axis=2)\n",
    "        train_labels=np.concatenate((train_labels,train_labels_copy),axis=2)\n",
    "    del train_imgs_copy,train_labels_copy\n",
    "\n",
    "val_list = data_list.val_data()\n",
    "# load both val data and its cropped images\n",
    "print('loading val imgs')\n",
    "val_label_orig,val_img_crop,val_label_crop,pixel_val_list=load_val_imgs(val_list,dt,orig_img_dt)\n",
    "\n",
    "# load unlabeled images\n",
    "unl_list = data_list.unlabeled_data()\n",
    "print('loading unlabeled imgs')\n",
    "unlabeled_imgs=dt.load_img_labels(unl_list,label_present=0)\n",
    "\n",
    "# get test list\n",
    "print('get test imgs list')\n",
    "test_list = data_list.test_data()\n",
    "struct_name=cfg.struct_name\n",
    "val_step_update=cfg.val_step_update\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "\n",
    "def get_samples(labeled_imgs,unlabeled_imgs):\n",
    "    # sample z vectors from Gaussian Distribution\n",
    "    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "    #sample Unlabeled data shuffled batch\n",
    "    unld_img_batch=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    #sample Labelled data shuffled batch\n",
    "    ld_img_batch=shuffle_minibatch([labeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    return z_samples,ld_img_batch,unld_img_batch\n",
    "\n",
    "def plt_func(sess,ae,save_dir,z_samples,ld_img_batch,unld_img_batch,index=0):\n",
    "    # plot intensity transformed images for an fixed input image and different sampled z values\n",
    "    ld_img_tmp=np.zeros_like(ld_img_batch)\n",
    "    # select one 2D image from the batch and apply different z's sampled over this selected image\n",
    "    for i in range(0,20):\n",
    "        ld_img_tmp[i,:,:,0]=ld_img_batch[index,:,:,0]\n",
    "\n",
    "    int_vec,y_int_deformed,z_cost=sess.run([ae['int_c1'],ae['y_int'],ae['z_cost']], feed_dict={ae['x']: ld_img_tmp, ae['z']:z_samples,\\\n",
    "                          ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: False})\n",
    "\n",
    "    f1_util.plot_intensity_transformed_imgs(ld_img_tmp,y_int_deformed,int_vec,save_dir,index=index)\n",
    "\n",
    "    # Plot gif of all the transformed images generated for the fixed input image\n",
    "    #f1_util.write_gif_func(ip_img=y_int_deformed, imsize=(cfg.img_size_x,cfg.img_size_y),save_dir=save_dir,index=index)\n",
    "\n",
    "######################################\n",
    "# Define checkpoint file to save CNN architecture and learnt hyperparameters\n",
    "checkpoint_filename='unet_'+str(params.dataset)\n",
    "logs_path = str(save_dir)+'tensorflow_logs/'\n",
    "best_model_dir=str(save_dir)+'best_model/'\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# Define additive intensity field generator model graph\n",
    "ae = model.intensity_transform_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n",
    "                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n",
    "                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n",
    "                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_i=params.lamda_l1_i)\n",
    "\n",
    "######################################\n",
    "#  training parameters\n",
    "start_epoch=0\n",
    "n_epochs = 10000\n",
    "disp_step=400\n",
    "print_step=2000\n",
    "# no of iterations to train just the segmentation network using the labeled data without any cGAN generated data\n",
    "seg_tr_limit=400\n",
    "mean_f1_val_prev=0.1\n",
    "threshold_f1=0.00001\n",
    "pathlib.Path(best_model_dir).mkdir(parents=True, exist_ok=True)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# define graph to compute 1 hot encoding for an input label\n",
    "df_ae= model.deform_net()\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "#writer for train summary\n",
    "train_writer = tf.summary.FileWriter(logs_path)\n",
    "#writer for dice score and val summary\n",
    "dsc_writer = tf.summary.FileWriter(logs_path)\n",
    "val_sum_writer = tf.summary.FileWriter(logs_path)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# create a session and initialize variable to use the graph\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Save training data\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "######################################\n",
    "\n",
    "# Run for n_epochs\n",
    "for epoch_i in range(start_epoch,n_epochs):\n",
    "\n",
    "    # sample z's from Gaussian Distribution\n",
    "    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "    # sample Unlabeled shuffled batch\n",
    "    unld_img_batch=shuffle_minibatch([unlabeled_imgs],batch_size=int(cfg.batch_size),num_channels=cfg.num_channels,labels_present=0,axis=2)\n",
    "\n",
    "    # sample Labeled shuffled batch\n",
    "    ld_img_batch,ld_label_batch=shuffle_minibatch([train_imgs,train_labels],batch_size=cfg.batch_size,num_channels=cfg.num_channels,axis=2)\n",
    "\n",
    "    if(cfg.aug_en==1):\n",
    "        # Apply affine transformations\n",
    "        ld_img_batch,ld_label_batch=augmentation_function([ld_img_batch,ld_label_batch],dt)\n",
    "        unld_img_batch=augmentation_function([unld_img_batch],dt,labels_present=0)\n",
    "\n",
    "    ld_img_batch_tmp=np.copy(ld_img_batch)\n",
    "    # Compute 1 hot encoding of the segmentation mask labels\n",
    "    ld_label_batch_1hot = sess.run(df_ae['y_tmp_1hot'],feed_dict={df_ae['y_tmp']:ld_label_batch})\n",
    "\n",
    "    if(epoch_i>=seg_tr_limit):\n",
    "        # sample the batch of images and apply deformation field generated by the Generator network on these which are used for the remaining 9500 epochs\n",
    "        # Batch comprosed of both deformed image,label pairs and original affine transformed image, label pairs\n",
    "        # Here, the labels do not change on application of intensity transformation since it is an additive operation\n",
    "        ld_label_batch_tmp=np.copy(ld_label_batch)\n",
    "        ###########################\n",
    "        # use additive intensity field cGAN to generate additional augmented image,label pairs from labeled samples\n",
    "        _,ld_img_batch=sess.run([ae['int_c1'],ae['y_int']],\\\n",
    "                                    feed_dict={ae['x']: ld_img_batch_tmp, ae['z']:z_samples, ae['train_phase']: False})\n",
    "        ld_label_batch=ld_label_batch_1hot\n",
    "\n",
    "        ###########################\n",
    "        # shuffle the quantity/number of images chosen from intensity field cGAN augmented images and rest are original images with conventional affine transformations\n",
    "        no_orig=np.random.randint(5, high=15)\n",
    "        ld_img_batch[0:no_orig] = ld_img_batch_tmp[0:no_orig]\n",
    "        if(params.en_1hot==1):\n",
    "            ld_label_batch = ld_label_batch_1hot\n",
    "        else:\n",
    "            ld_label_batch = ld_label_batch_tmp\n",
    "\n",
    "        #Pick equal number of images from each category\n",
    "        # ld_img_batch[0:10]=ld_img_batch_tmp[0:10]\n",
    "        # ld_label_batch[0:10]=ld_label_batch_1hot[0:10]\n",
    "\n",
    "    elif(epoch_i<seg_tr_limit):\n",
    "        # sample only labeled data batches to optimize only Segmentation Network for initial 500 epochs\n",
    "        ld_img_batch=ld_img_batch\n",
    "        unld_img_batch=unld_img_batch\n",
    "        ld_label_batch=ld_label_batch_1hot\n",
    "\n",
    "    if(epoch_i<seg_tr_limit):\n",
    "        #Optimize only Segmentation Network for initial 500 epochs\n",
    "        train_summary,_ =sess.run([ae['seg_summary'],ae['optimizer_unet_seg']], feed_dict={ae['x']: ld_img_batch, ae['y_l']: ld_label_batch,\\\n",
    "                                   ae['select_mask']: False, ae['train_phase']: True})\n",
    "\n",
    "    if(epoch_i>seg_tr_limit):\n",
    "        #Optimize Generator (G), Discriminator (D) and Segmentation (S) networks for the remaining 9500 epochs\n",
    "\n",
    "        # update both Generator and Segmentation Net parameters in the framework using total loss value\n",
    "        train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_l2_both_gen_unet']], feed_dict={ae['x']: ld_img_batch,ae['y_l']: ld_label_batch,\\\n",
    "                                   ae['z']:z_samples, ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n",
    "\n",
    "        # update Discriminator Net (D) parameters in the setup using only discriminator loss\n",
    "        train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_disc']], feed_dict={ae['x']: ld_img_batch,ae['z']:z_samples,\\\n",
    "                              ae['y_l']: ld_label_batch,ae['x_unl']: unld_img_batch, ae['select_mask']: True, ae['train_phase']: True})\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        train_writer.add_summary(train_summary, epoch_i)\n",
    "        train_writer.flush()\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        ##Save the model with best DSC for Validation Image\n",
    "        mean_f1_arr=[]\n",
    "        f1_arr=[]\n",
    "        for val_id_no in range(0,len(val_list)):\n",
    "            val_img_crop_tmp=val_img_crop[val_id_no]\n",
    "            val_label_crop_tmp=val_label_crop[val_id_no]\n",
    "            val_label_orig_tmp=val_label_orig[val_id_no]\n",
    "            pixel_size_val=pixel_val_list[val_id_no]\n",
    "\n",
    "            # Compute segmentation mask and dice_score for each validation subject\n",
    "            pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, val_img_crop_tmp)\n",
    "            re_pred_mask_sys,f1_val = f1_util.reshape_img_and_f1_score(pred_sf_mask, val_label_orig_tmp, pixel_size_val)\n",
    "\n",
    "            #concatenate dice scores of each val image\n",
    "            mean_f1_arr.append(np.mean(f1_val[1:cfg.num_classes]))\n",
    "            f1_arr.append(f1_val[1:cfg.num_classes])\n",
    "\n",
    "        #avg mean over 2 val subjects\n",
    "        mean_f1_arr = np.asarray(mean_f1_arr)\n",
    "        mean_f1 = np.mean(mean_f1_arr)\n",
    "        f1_arr = np.asarray(f1_arr)\n",
    "\n",
    "        if ((epoch_i%disp_step == 0) or (epoch_i==n_epochs-1)):\n",
    "            print('mean_f1',epoch_i, mean_f1)\n",
    "        if (mean_f1-mean_f1_val_prev>threshold_f1 and epoch_i!=start_epoch):\n",
    "            print(\"prev f1_val; present_f1_val\", mean_f1_val_prev, mean_f1, mean_f1_arr)\n",
    "            mean_f1_val_prev = mean_f1\n",
    "            # to save the best model with maximum dice score over the entire n_epochs\n",
    "            print(\"best model saved at epoch no. \", epoch_i)\n",
    "            mp_best = str(best_model_dir) + str(checkpoint_filename) + '_best_model_epoch_' + str(epoch_i) + '.ckpt'\n",
    "            saver.save(sess, mp_best)\n",
    "\n",
    "        #calc. and save validation image dice summary\n",
    "        dsc_summary_msg = sess.run(ae['val_dsc_summary'], feed_dict={ae['rv_dice']:np.mean(f1_arr[:,0]),\\\n",
    "                                ae['myo_dice']:np.mean(f1_arr[:,1]),ae['lv_dice']:np.mean(f1_arr[:,2]),ae['mean_dice']: mean_f1})\n",
    "\n",
    "    if ((epoch_i==n_epochs-1) and (epoch_i != start_epoch)):\n",
    "        # model saved at last epoch\n",
    "        mp = str(save_dir) + str(checkpoint_filename) + '_epochs_' + str(epoch_i) + '.ckpt'\n",
    "        saver.save(sess, mp)\n",
    "        try:\n",
    "            mp_best\n",
    "        except NameError:\n",
    "            mp_best=mp\n",
    "\n",
    "sess.close()\n",
    "######################################\n",
    "# restore best model and predict segmentations on test subjects\n",
    "saver_new = tf.train.Saver()\n",
    "sess_new = tf.Session(config=config)\n",
    "saver_new.restore(sess_new, mp_best)\n",
    "print(\"best model chkpt\",mp_best)\n",
    "print(\"Model restored\")\n",
    "\n",
    "#########################\n",
    "# To compute inference on test images on the model that yields best dice score on validation images\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir,orig_img_dt,test_list,struct_name)\n",
    "#########################\n",
    "# To plot the generated augmented images from the trained deformation cGAN\n",
    "for j in range(0,5):\n",
    "    z_samples,ld_img_batch,unld_img_batch=get_samples(train_imgs,unlabeled_imgs)\n",
    "    save_dir_tmp=str(save_dir)+'/ep_best_model/'\n",
    "    plt_func(sess_new,ae,save_dir_tmp,z_samples,ld_img_batch,unld_img_batch,index=j)\n",
    "######################################\n",
    "# To compute inference on validation images on the best model\n",
    "save_dir_tmp=str(save_dir)+'/val_imgs/'\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir_tmp,orig_img_dt,val_list,struct_name)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Htfi8elnNp4c"
   },
   "source": [
    "# Train Unet with trained GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W_67bO43M4_R"
   },
   "outputs": [],
   "source": [
    "ra_en_val=params.ra_en\n",
    "if(params.ra_en==1):\n",
    "    params.ra_en=True\n",
    "else:\n",
    "    params.ra_en=False\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    print('load acdc configs')\n",
    "    import experiment_init.init_acdc as cfg\n",
    "    import experiment_init.data_cfg_acdc as data_list\n",
    "else:\n",
    "    raise ValueError(params.dataset)\n",
    "\n",
    "######################################\n",
    "# class loaders\n",
    "# ####################################\n",
    "#  load dataloader object\n",
    "from dataloaders import dataloaderObj\n",
    "dt = dataloaderObj(cfg)\n",
    "\n",
    "if params.dataset == 'acdc':\n",
    "    print('set acdc img dataloader handle')\n",
    "    orig_img_dt=dt.load_acdc_imgs\n",
    "\n",
    "#  load model object\n",
    "from models import modelObj\n",
    "model = modelObj(cfg)\n",
    "\n",
    "#  load f1_utils object\n",
    "from f1_utils import f1_utilsObj\n",
    "f1_util = f1_utilsObj(cfg,dt)\n",
    "\n",
    "######################################\n",
    "#define save_dir for the model\n",
    "proj_save_name='tr_deform_and_int_cgans_data_aug/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)\n",
    "\n",
    "if(params.data_aug_seg==0):\n",
    "    save_dir=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/'+str(proj_save_name)+'/no_data_aug/'\n",
    "    cfg.aug_en=params.data_aug_seg\n",
    "else:\n",
    "    save_dir=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/'+str(proj_save_name)+'/with_data_aug/'\n",
    "\n",
    "save_dir=str(save_dir)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+\\\n",
    "         '_lamda_g_'+str(params.lamda_l1_g)+'_lamda_i_'+str(params.lamda_l1_i)+\\\n",
    "         '/'+str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+'/unet_model_dsc_loss_'+str(params.dsc_loss)+'_lr_seg_'+str(params.lr_seg)+'/'\n",
    "print('save_dir',save_dir)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# load train and val images\n",
    "train_list = data_list.train_data(params.no_of_tr_imgs,params.comb_tr_imgs)\n",
    "#print(train_list)\n",
    "#load train data cropped images directly\n",
    "print('loading train imgs')\n",
    "train_imgs,train_labels = dt.load_img_labels(train_list)\n",
    "\n",
    "if(params.no_of_tr_imgs=='tr1'):\n",
    "    train_imgs_copy=np.copy(train_imgs)\n",
    "    train_labels_copy=np.copy(train_labels)\n",
    "    while(train_imgs.shape[2]<cfg.batch_size):\n",
    "        train_imgs=np.concatenate((train_imgs,train_imgs_copy),axis=2)\n",
    "        train_labels=np.concatenate((train_labels,train_labels_copy),axis=2)\n",
    "    del train_imgs_copy,train_labels_copy\n",
    "\n",
    "val_list = data_list.val_data()\n",
    "#print(val_list)\n",
    "#load both val data and its cropped images\n",
    "print('loading val imgs')\n",
    "val_label_orig,val_img_crop,val_label_crop,pixel_val_list=load_val_imgs(val_list,dt,orig_img_dt)\n",
    "#print(pixel_val_list)\n",
    "\n",
    "# get test list\n",
    "print('get test imgs list')\n",
    "test_list = data_list.test_data()\n",
    "struct_name=cfg.struct_name\n",
    "val_step_update=cfg.val_step_update\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# Define checkpoint file to save CNN architecture and learnt hyperparameters\n",
    "checkpoint_filename='unet_'+str(params.dataset)\n",
    "logs_path = str(save_dir)+'tensorflow_logs/'\n",
    "best_model_dir=str(save_dir)+'best_model/'\n",
    "######################################\n",
    "\n",
    "########################################################################\n",
    "#load deformation field generator net\n",
    "########################################################################\n",
    "# Define the model graph\n",
    "tf.reset_default_graph()\n",
    "ae_geo = model.spatial_generator_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n",
    "                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n",
    "                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n",
    "                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_g=params.lamda_l1_g)\n",
    "\n",
    "# define model path\n",
    "model_path=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/tr_deformation_cgan_unet/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)+'/'\n",
    "\n",
    "if(params.data_aug_seg==0):\n",
    "    model_path=str(model_path)+'no_data_aug/'\n",
    "    cfg.aug_en=params.data_aug_seg\n",
    "else:\n",
    "    model_path=str(model_path)+'with_data_aug/'\n",
    "\n",
    "model_path=str(model_path)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+'_lamda_g_'+str(params.lamda_l1_g)+'/'+\\\n",
    "         str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+\\\n",
    "         '/unet_model_beta1_'+str(params.beta_val)+'_lr_seg_'+str(params.lr_seg)+'_lr_gen_'+str(params.lr_gen)+'_lr_disc_'+str(params.lr_disc)+'/'\n",
    "\n",
    "mp=get_max_chkpt_file(model_path)\n",
    "print('loading deformation field cGAN checkpoint file',mp)\n",
    "# create a session and load the parameters learned\n",
    "saver_geo = tf.train.Saver(max_to_keep=2)\n",
    "sess_geo = tf.Session(config=config)\n",
    "saver_geo.restore(sess_geo,mp)\n",
    "######################################\n",
    "\n",
    "########################################################################\n",
    "#load additive intensity field generator net\n",
    "########################################################################\n",
    "# Define the model graph\n",
    "tf.reset_default_graph()\n",
    "ae_int = model.intensity_transform_cgan_unet(learn_rate_gen=params.lr_gen,learn_rate_disc=params.lr_disc,\\\n",
    "                        beta1_val=params.beta_val,gan_type=params.gan_type,ra_en=params.ra_en,\\\n",
    "                        learn_rate_seg=params.lr_seg,dsc_loss=params.dsc_loss,en_1hot=params.en_1hot,\\\n",
    "                        lamda_dsc=params.lamda_dsc,lamda_adv=params.lamda_adv,lamda_l1_i=params.lamda_l1_i)\n",
    "\n",
    "# define model path\n",
    "model_path=str(cfg.base_dir)+'/models/'+str(params.dataset)+'/tr_intensity_cgan_unet/ra_en_'+str(ra_en_val)+'_gantype_'+str(params.gan_type)+'/'\n",
    "\n",
    "if(params.data_aug_seg==0):\n",
    "    model_path=str(model_path)+'no_data_aug/'\n",
    "    cfg.aug_en=params.data_aug_seg\n",
    "else:\n",
    "    model_path=str(model_path)+'with_data_aug/'\n",
    "\n",
    "model_path=str(model_path)+'lamda_dsc_'+str(params.lamda_dsc)+'_lamda_adv_'+str(params.lamda_adv)+'_lamda_i_'+str(params.lamda_l1_i)+'/'+\\\n",
    "         str(params.no_of_tr_imgs)+'/'+str(params.comb_tr_imgs)+'_v'+str(params.ver)+\\\n",
    "         '/unet_model_beta1_'+str(params.beta_val)+'_lr_seg_'+str(params.lr_seg)+'_lr_gen_'+str(params.lr_gen)+'_lr_disc_'+str(params.lr_disc)+'/'\n",
    "\n",
    "mp=get_max_chkpt_file(model_path)\n",
    "print('loading additive intensity field cGAN checkpoint file ',mp)\n",
    "# create a session and load the parameters learned\n",
    "saver_int = tf.train.Saver(max_to_keep=2)\n",
    "sess_int = tf.Session(config=config)\n",
    "saver_int.restore(sess_int,mp)\n",
    "\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "#  training parameters\n",
    "start_epoch=0\n",
    "n_epochs = 10000\n",
    "disp_step=500\n",
    "mean_f1_val_prev=0.1\n",
    "threshold_f1=0.00001\n",
    "debug_en=0\n",
    "pathlib.Path(best_model_dir).mkdir(parents=True, exist_ok=True)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# define current graph - unet\n",
    "tf.reset_default_graph()\n",
    "ae = model.unet(learn_rate_seg=params.lr_seg,en_1hot=params.en_1hot,dsc_loss=params.dsc_loss)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# define deformations net for labels\n",
    "df_ae= model.deform_net()\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "#writer for train summary\n",
    "train_writer = tf.summary.FileWriter(logs_path)\n",
    "#writer for dice score and val summary\n",
    "dsc_writer = tf.summary.FileWriter(logs_path)\n",
    "val_sum_writer = tf.summary.FileWriter(logs_path)\n",
    "######################################\n",
    "\n",
    "######################################\n",
    "# create a session and initialize variable to use the graph\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Save training data\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "######################################\n",
    "\n",
    "# Run for n_epochs\n",
    "for epoch_i in range(start_epoch,n_epochs):\n",
    "\n",
    "    # sample z's from Gaussian Distribution\n",
    "    z_samples = np.random.normal(loc=0.0, scale=1.0, size=(cfg.batch_size, params.z_lat_dim)).astype(np.float32)\n",
    "\n",
    "    #sample Labelled data shuffled batch\n",
    "    ld_img_batch,ld_label_batch=shuffle_minibatch([train_imgs,train_labels],batch_size=cfg.batch_size,num_channels=cfg.num_channels,axis=2)\n",
    "    if(cfg.aug_en==1):\n",
    "        # Apply affine transformations\n",
    "        ld_img_batch,ld_label_batch=augmentation_function([ld_img_batch,ld_label_batch],dt)\n",
    "\n",
    "    ld_img_batch_orig_tmp=np.copy(ld_img_batch)\n",
    "    ld_label_batch_orig_tmp=np.copy(ld_label_batch)\n",
    "    # Compute 1 hot encoding of the segmentation mask labels\n",
    "    ld_label_batch_orig_1hot = sess.run(df_ae['y_tmp_1hot'],feed_dict={df_ae['y_tmp']:ld_label_batch_orig_tmp})\n",
    "\n",
    "    ############################\n",
    "    ## use Deformation field cGAN to generate additional augmented image,label pairs from labeled samples\n",
    "    flow_vec,ld_img_batch_geo=sess_geo.run([ae_geo['flow_vec'],ae_geo['y_trans']],\\\n",
    "                                feed_dict={ae_geo['x_l']: ld_img_batch_orig_tmp, ae_geo['z']:z_samples, ae_geo['train_phase']: False})\n",
    "\n",
    "    ld_label_batch_geo=sess.run([df_ae['deform_y_1hot']],feed_dict={df_ae['y_tmp']:ld_label_batch_orig_tmp,df_ae['flow_v']:flow_vec})\n",
    "    ld_label_batch_geo=ld_label_batch_geo[0]\n",
    "\n",
    "    ############################\n",
    "    # use additive Intensity field cGAN to generate additional augmented image,label pairs from labeled samples\n",
    "    int_c1,ld_img_batch_int=sess_int.run([ae_int['int_c1'],ae_int['y_int']], feed_dict={ae_int['x']: ld_img_batch_orig_tmp, ae_int['z']:z_samples, ae_int['train_phase']: False})\n",
    "    ld_label_batch_int = ld_label_batch_orig_1hot\n",
    "\n",
    "    ############################\n",
    "    # use additive intensity field cGAN over augmented images generated from deformation field cGAN to create augmented images \\\n",
    "    # that have both spatial deformations and intensity transformations applied in them\n",
    "    ld_img_batch_geo_tmp=np.copy(ld_img_batch_geo)\n",
    "    int_c1,ld_img_batch_geo_int=sess_int.run([ae_int['int_c1'],ae_int['y_int']], feed_dict={ae_int['x']: ld_img_batch_geo_tmp, ae_int['z']:z_samples, ae_int['train_phase']: False})\n",
    "    ld_label_batch_geo_int = np.copy(ld_label_batch_geo)\n",
    "\n",
    "    # shuffle the quantity/number of images chosen from \n",
    "    # deformation field cGAN --> no_g,\n",
    "    # intensity field cGAN   --> no_i,\n",
    "    # both cGANs             --> no_b,\n",
    "    # and rest (batch_size - (no_g+no_i+no_b)) are original images with conventional affine transformations.\n",
    "    no_g=np.random.randint(1, high=5)\n",
    "    no_i=np.random.randint(5, high=10)\n",
    "    no_b=np.random.randint(10, high=15)\n",
    "\n",
    "    ld_img_batch=ld_img_batch_orig_tmp\n",
    "    ld_label_batch=ld_label_batch_orig_1hot\n",
    "\n",
    "    ld_img_batch[0:no_g] = ld_img_batch_geo[0:no_g]\n",
    "    ld_label_batch[0:no_g] = ld_label_batch_geo[0:no_g]\n",
    "    ld_img_batch[no_g:no_i] = ld_img_batch_int[no_g:no_i]\n",
    "    ld_label_batch[no_g:no_i] = ld_label_batch_int[no_g:no_i]\n",
    "    ld_img_batch[no_i:no_b] = ld_img_batch_geo_int[no_i:no_b]\n",
    "    ld_label_batch[no_i:no_b] = ld_label_batch_geo_int[no_i:no_b]\n",
    "\n",
    "    #Optimer over this batch of images\n",
    "    train_summary,_ =sess.run([ae['train_summary'],ae['optimizer_unet_seg']], feed_dict={ae['x']: ld_img_batch, ae['y_l']: ld_label_batch,\\\n",
    "                               ae['select_mask']: False, ae['train_phase']: True})\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        train_writer.add_summary(train_summary, epoch_i)\n",
    "        train_writer.flush()\n",
    "\n",
    "    if(epoch_i%val_step_update==0):\n",
    "        ##Save the model with best DSC for Validation Image\n",
    "        mean_f1_arr=[]\n",
    "        f1_arr=[]\n",
    "        for val_id_no in range(0,len(val_list)):\n",
    "            val_img_crop_tmp=val_img_crop[val_id_no]\n",
    "            val_label_crop_tmp=val_label_crop[val_id_no]\n",
    "            val_label_orig_tmp=val_label_orig[val_id_no]\n",
    "            pixel_size_val=pixel_val_list[val_id_no]\n",
    "\n",
    "            # Compute segmentation mask and dice_score for each validation subject\n",
    "            pred_sf_mask = f1_util.calc_pred_sf_mask_full(sess, ae, val_img_crop_tmp)\n",
    "            re_pred_mask_sys,f1_val = f1_util.reshape_img_and_f1_score(pred_sf_mask, val_label_orig_tmp, pixel_size_val)\n",
    "\n",
    "            #concatenate dice scores of each val image\n",
    "            mean_f1_arr.append(np.mean(f1_val[1:cfg.num_classes]))\n",
    "            f1_arr.append(f1_val[1:cfg.num_classes])\n",
    "\n",
    "        #avg mean over 2 val subjects\n",
    "        mean_f1_arr=np.asarray(mean_f1_arr)\n",
    "        mean_f1=np.mean(mean_f1_arr)\n",
    "        f1_arr=np.asarray(f1_arr)\n",
    "\n",
    "        if (mean_f1-mean_f1_val_prev>threshold_f1 and epoch_i!=start_epoch):\n",
    "            print(\"prev f1_val; present_f1_val\", mean_f1_val_prev, mean_f1, mean_f1_arr)\n",
    "            mean_f1_val_prev = mean_f1\n",
    "\n",
    "            # to save the best model with maximum dice score over the entire n_epochs\n",
    "            print(\"best model saved at epoch no. \", epoch_i)\n",
    "            mp_best = str(best_model_dir) + str(checkpoint_filename) + '_best_model_epoch_' + str(epoch_i) + '.ckpt'\n",
    "            saver.save(sess, mp_best)\n",
    "\n",
    "        #calc. and save validation image dice summary\n",
    "        dsc_summary_msg = sess.run(ae['val_dsc_summary'], feed_dict={ae['rv_dice']:np.mean(f1_arr[:,0]),\\\n",
    "                                ae['myo_dice']:np.mean(f1_arr[:,1]),ae['lv_dice']:np.mean(f1_arr[:,2]),ae['mean_dice']: mean_f1})\n",
    "        val_sum_writer.add_summary(dsc_summary_msg, epoch_i)\n",
    "        val_sum_writer.flush()\n",
    "\n",
    "    if ((epoch_i==n_epochs-1) and (epoch_i != start_epoch)):\n",
    "        # model saved at last epoch\n",
    "        mp = str(save_dir) + str(checkpoint_filename) + '_epochs_' + str(epoch_i) + '.ckpt'\n",
    "        saver.save(sess, mp)\n",
    "        try:\n",
    "            mp_best\n",
    "        except NameError:\n",
    "            mp_best=mp\n",
    "\n",
    "sess.close()\n",
    "######################################\n",
    "# restore best model and predict segmentations on test subjects\n",
    "saver_new = tf.train.Saver()\n",
    "sess_new = tf.Session(config=config)\n",
    "saver_new.restore(sess_new, mp_best)\n",
    "print(\"best model chkpt\",mp_best)\n",
    "print(\"Model restored\")\n",
    "\n",
    "#########################\n",
    "# To compute inference on test images on the model that yields best dice score on validation images\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir,orig_img_dt,test_list,struct_name)\n",
    "######################################\n",
    "# To compute inference on validation images on the best model\n",
    "save_dir_tmp=str(save_dir)+'/val_imgs/'\n",
    "f1_util.pred_segs_acdc_test_subjs(sess_new,ae,save_dir_tmp,orig_img_dt,val_list,struct_name)\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aQSIfVO4TuWI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model-training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
